什么是正则化,是指防止模型欠拟合与过拟合的操作,通过惩罚限制模型的复杂度,提高模型的泛化能力

卷积神经网络:重点考虑:1.平移不变性2.局部性原则.

卷积核跟权重一样随机初始化

块（block）可以描述单个层、由多个层组成的组件或整个模型本身。 使用块进行抽象的一个好处是可以将一些块组合成更大的组件， 这一过程通常是递归的，如 图5.1.1所示。 通过定义代码来按需生成任意复杂度的块， 我们可以通过简洁的代码实现复杂的神经网络。
![picture 0](../images/f20ddcc64f2fee37bda290869ff21757138760682269ddcffd2c48f57bfc7954.png)  

填充
防止丢失边缘像素
![picture 1](../images/56c8c9c8b1361cb54ead5955e6c7bc6ec54cff949d56bc7144e8799ba71c0648.png)  

步幅
![picture 2](../images/ee0f0efa12e2b6b171de5d7874295400f74045c77e975fa021e16cfe255676a9.png)  

pooling汇聚


通过固定窗口对特征图进行降维，减小特征图的宽度和高度。 和下采样（Subsampling）
![picture 3](../images/a4a3751d30eefeda6e9f4547bfc442b7aa3fa7e8b569d6bea7f6b4bc7f412050.png)  

监督学习和无监督学习:无监督学习没有标签数据,常用于检测异常.

L1正则化和L2正则化的区别?:L1是求权重的绝对值之和,可以生成稀疏模型，利于特征选择。L2是求权重的各个元素的平方和再求平方根.防止模型过拟合.

交叉检验:数据集分成K份,K-1训练,1份检验,然后一轮后重新K-1份进行训练数据.

ROC曲线就是真阳性和假阳性在不同阈值下绘制的曲线,越靠近左上角模型性能越好.





